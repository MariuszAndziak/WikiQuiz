{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install spacy\n",
    "\n",
    "ściągnąć polski model z \n",
    "http://zil.ipipan.waw.pl/SpacyPL?action=AttachFile&do=view&target=pl_spacy_model-0.1.0.tar.gz\n",
    "i zainstalować: python -m pip install PATH/TO/pl_spacy_model-x.x.x.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pliki json z rzeczownikami pobrane z:\n",
    "https://github.com/tombusby/PolishCaseTrainer/tree/master/polish_case_trainer/word/word-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ładowanie modułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import spacy\n",
    "import re\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pl_spacy_model')\n",
    "from spacy.lang.pl.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_page = 'https://pl.wikipedia.org/wiki/Psychoza'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utworzenie stałych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_DICT = {'ą':('\\u0105', '%C4%85','\\\\xc4\\\\85'), 'ę':('\\u0119', '%C4%99', '\\\\xc4\\\\99'), 'ł':('\\u0142', '%C5%82','\\\\xc5\\\\82'), 'ś':('\\u015b', '%C5%9B','\\\\xc5\\\\9b'),\n",
    "            'ć':('\\u0107', '%C4%87', '\\\\xc4\\\\87'), 'ń':('\\u0144', '%C5%84','\\\\xc5\\\\84'), 'ó':('\\u00f3', '%C3%B3','\\\\xc3\\\\xb3'), 'ź':('\\u017a', '%C5%BA','\\\\xc5\\\\ba'), \n",
    "             'ż':('\\u017c', '%C5%BC','\\\\xc5\\\\bc'), 'Ł':('\\u0141', '%C5%81', '\\\\xc5\\\\81'), 'Ś':('\\u015a', '%C5%9A','\\\\xc5\\\\9a'), 'Ć':('\\u0106', '%C4%86', '\\\\xc4\\\\86'), \n",
    "             'Ź':('\\u0106', '%C4%86','\\\\xc4\\\\86'), 'Ż':('\\u017b', '%C5%Bb', '\\\\xc5\\\\bb')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "przypadki = ['mianownik', 'dopełniacz', 'celownik', 'biernik', 'narzędnik', 'miejscownik', 'wołacz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECLINATION_FORM = {'accusative' : 'biernik', 'instrumental' : 'narzędnik', 'dative' : 'celownik', 'locative' : 'miejscownik', 'genitive' : 'dopełniacz', \n",
    "                    'nominative' : 'mianownik', 'vocative' : 'wołacz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ładowanie treści"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wiki_page(url):\n",
    "    # Generator służący do ładowania strony\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    wiki = bs4.BeautifulSoup(res.text, \"html.parser\")\n",
    "    for _ in wiki.select('p'): #Bierzemy to co jest zawarte między tagami <p> </p>\n",
    "        yield _.getText()\n",
    "\n",
    "\n",
    "def prepare_text(brackets=\"[]\"):\n",
    "    # Buduwanie stringa z generatora i usuwanie nowych linii i no break-space\n",
    "    res = []\n",
    "    for _ in load_wiki_page(sample_page):\n",
    "        res.append(_.replace('\\n','').replace('\\xa0',''))\n",
    "    tekst = ''.join(res)\n",
    "    \n",
    "    # Usuwanie wszystkiego co znajduje się między nawiasami [], np. wszystkie przypisy typu: wyraz[14]\n",
    "    count = [0] * (len(brackets) // 2)\n",
    "    saved_chars = []\n",
    "    for character in tekst:\n",
    "        for i, b in enumerate(brackets):\n",
    "            if character == b: \n",
    "                kind, is_close = divmod(i, 2)\n",
    "                count[kind] += (-1)**is_close \n",
    "                if count[kind] < 0: \n",
    "                    count[kind] = 0 \n",
    "                else:  \n",
    "                    break\n",
    "        else: \n",
    "            if not any(count): \n",
    "                saved_chars.append(character)\n",
    "    return ''.join(saved_chars)\n",
    "\n",
    "tekst = prepare_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zamiana tekst na nlp i utworzenie zdań"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(tekst)\n",
    "sentences= [sentence for sentence in doc.sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja oczyszczająca słowa z tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_upN(text, inc_dot = False):\n",
    "    # Potrzebna dla funkcji 'Najczęściej używane słowa'\n",
    "    # usuwa przecinki, kropki, niepotrzebne spacje\n",
    "    from string import digits, punctuation\n",
    "    if inc_dot: # Czy kropka (.) ma być uwzględniona\n",
    "        p = punctuation.replace('.','') + '—…' \n",
    "    else:\n",
    "        p = punctuation + '—…'\n",
    "    irr = len(digits + p)\n",
    "    change = text.maketrans(digits + p, ' '*irr)\n",
    "    result = text.translate(change)\n",
    "    return result.rstrip().lstrip()\n",
    "\n",
    "words_clean = [clean_upN(word) for word in tekst.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Najczęściej używane słowa w tekście"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_words_func(n, output_words_only = False):\n",
    "    from spacy.lang.pl.stop_words import STOP_WORDS\n",
    "    from string import punctuation\n",
    "    \n",
    "    accurance = {}\n",
    "    for word in words_clean:\n",
    "        if word.lower() not in STOP_WORDS and word.lower() not in punctuation +'–':\n",
    "            accurance[word] = accurance.get(word,0) +1\n",
    "    \n",
    "    #sortujemy słowa względem popularności\n",
    "    accurance_sort = [(word, acc) for word, acc in sorted(accurance.items(), key = lambda item: item[1], reverse=True) if word !=''][:n]\n",
    "    \n",
    "    #czy funkcja ma zwrócić same słowa, czy słowa wraz z częstotliwościami wystąpień\n",
    "    if output_words_only:\n",
    "        return [item[0] for item in accurance_sort]\n",
    "    else:\n",
    "        return accurance_sort\n",
    "    \n",
    "most_common_words = most_common_words_func(50, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stworzenie sekwencji par słów bazujących ma łańcuchu Marcova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs_gen(words_clean):\n",
    "    # Generator pary krotek: (wyraz pierwszy, wyraz drugi), \n",
    "    # (wyraz drugi, wyraz trzeci) itp...\n",
    "    for i in range(len(words_clean)-1): \n",
    "        yield (words_clean[i], words_clean[i+1]) \n",
    "\n",
    "def make_pairs(treshold = 3):\n",
    "    from collections import Counter\n",
    "    pairs = make_pairs_gen(words_clean)\n",
    "    \n",
    "    # Jeżeli słowa nie było w słowniku, dodaj je jako klucz\n",
    "    # jeżeli zaś już było rozszerz jego value (listę) o kolejny element \n",
    "    pairs_dict = {}\n",
    "    for w1, w2 in pairs:\n",
    "        if w1 in pairs_dict.keys():\n",
    "            pairs_dict[w1].append(w2)\n",
    "        else:\n",
    "            pairs_dict[w1] = [w2]\n",
    "    \n",
    "    # Utwórz słownik, który będzie przechowywał zliczenia słów\n",
    "    pairs_dict_app = dict()\n",
    "    for key in pairs_dict.keys():\n",
    "        pairs_dict_app[key] = dict(Counter(pairs_dict[key]))\n",
    "    \n",
    "    # Jeżeli słowo (value) wystąpiło więcej lub tyle samo razy co zadany treshold i nie należy ono, ani\n",
    "    # jego para (value - element listy) do  STOP_WORD, wtedy dodaj je wraz z parą do nowego słownika\n",
    "    pairs_sort = dict()\n",
    "    for key, val in pairs_dict_app.items():\n",
    "        w, n = [(word, val) for word, val in sorted(pairs_dict_app[key].items(), key = lambda item: item[1], reverse = True)][0]\n",
    "        if n >=treshold and w != '' and key not in STOP_WORDS and w not in STOP_WORDS:\n",
    "            pairs_sort[key] = w\n",
    "    return pairs_sort\n",
    "\n",
    "pairs_sort = make_pairs(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stanie': 'psychozy'}"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Łączenie par key i value słownika w jedno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glue_dict():\n",
    "    return {(k +' ' + str(v)) for (k, v) in pairs_sort.items()}\n",
    "sequences = glue_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stanie psychozy'}"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stworzenie podmiotów (enteties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ents():\n",
    "    # Zwraca słownik: entsD = {rodzaj_podmiotu: nazwa podmiotu}\n",
    "    # np. {'geogName': 'Afryka'}\n",
    "    entsD = defaultdict(set)\n",
    "    for token in doc.ents:\n",
    "        entsD[token.label_].add(token.text)\n",
    "    return entsD\n",
    "\n",
    "ents_dict = gen_ents()\n",
    "\n",
    "def gen_ents_dict():    \n",
    "    ents = list()\n",
    "    for v in ents_dict.values():\n",
    "        ents.append(v) # Tworzy listę setów z genEnts() bez nazw\n",
    "    ents_full = set(y for x in ents for y in x) # Wrzuca wszystkie podmioty do jednego seta\n",
    "    return ents, ents_full \n",
    "\n",
    "ents, ents_full = gen_ents_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'persName': {'Ernst von Feuchtersleben', 'Levine', 'Zigler'},\n",
       "             'date': {'1845'},\n",
       "             'geogName': {'Księżycu'},\n",
       "             'placeName': {'Gdyni', 'Krakowie'}})"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poprawianie ents_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in ents_dict.items():\n",
    "    if k == 'geogName':\n",
    "        gN = {elem for elem in v if elem[0].isupper()}\n",
    "    elif k == 'persName':\n",
    "        pN = {elem for elem in v if elem[0].isupper()}\n",
    "    elif k == 'orgName':\n",
    "        oN = {elem for elem in v if elem[0].isupper()}\n",
    "    elif k == 'placeName':\n",
    "        plN = {elem for elem in v if elem[0].isupper()}\n",
    "\n",
    "if 'geogName' in ents_dict.keys():\n",
    "    ents_dict['geogName'] = gN\n",
    "if 'persName' in ents_dict.keys():\n",
    "    ents_dict['persName'] = pN\n",
    "if 'orgName' in ents_dict.keys():\n",
    "    ents_dict['orgName'] = oN\n",
    "if 'placeName' in ents_dict.keys():\n",
    "    ents_dict['placeName'] = plN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'persName': {'Ernst von Feuchtersleben', 'Levine', 'Zigler'},\n",
       "             'date': {'1845'},\n",
       "             'geogName': {'Księżycu'},\n",
       "             'placeName': {'Gdyni', 'Krakowie'}})"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja wstawiająca puste miejsce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_word_in_sent(word, sentence):\n",
    "    word = str(word)\n",
    "    sentence = str(sentence)\n",
    "    newSent = re.compile(re.escape(word), re.IGNORECASE)\n",
    "    return newSent.sub('_______________', sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja zwracająca wszystko co jesteśmy w stanie zidentyfikować (zdefiniowane grupy wyrazów, słowa częste i podmioty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_good_word(sent):\n",
    "    seq_list = [word for word in sequences if word  in str(sent)] # Zidentyfikowane grupy wyrazów (Marcov)\n",
    "    mcw_list = [word for word in most_common_words if word  in str(sent)] # Słowa częste\n",
    "    ents_list = [word for word in ents_full if word  in str(sent)] # Enteties (podmioty)\n",
    "    return seq_list + mcw_list + ents_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja zwracająca nazwę słownika z enteties, do którego należy dane słowo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_label_based_on_word(word):\n",
    "    if word in ents_full:\n",
    "        for key in ents_dict.keys():\n",
    "            for elem in ents_dict[key]:\n",
    "                if elem == word:\n",
    "                    return key\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja znajdująca niepoprawne odpowiedzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_bad_words_for_single(word, all_candidates = False):\n",
    "    # Jeżeli all_candidates = True, zwrócone będą również kandydaci, które algorytm brał pod uwagę\n",
    "    # ale ich nie uwzględnił\n",
    "    sl = dict()\n",
    "    all_c = []\n",
    "    dict_name = return_label_based_on_word(word) # Sprawdzenie do jakiego słownika należy słowo\n",
    "    if dict_name != '':\n",
    "        lista = []\n",
    "        while len(lista) <3: # Dopóki nie wygenerujemy 3 alternatywnych odpowiedzi...\n",
    "            cand = random.sample(ents_dict[dict_name],1)[0] # losuj dowolne słowo z tego samego słownika\n",
    "            all_c.append(cand) # i dodaj je do listy\n",
    "            if same_letters(cand, word) and different_lemma(cand, word): ###jeżeli pierwsze litery naszego słowa i kandydata\n",
    "                # się zgadzają oraz mają różną lemmę...\n",
    "                lista.append(cand) # dodaj tego kandydata do listy\n",
    "        sl[word] = list(set(lista)) # unikamy wielokrotnych powtórzeń tych samych słów alternatywnych\n",
    "    else:\n",
    "        sl[word] = ()\n",
    "    if all_candidates:\n",
    "        return sl, all_candidates\n",
    "    else:\n",
    "        return sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja upewniająca się, czy nie mamy do czynienia z tym samym słowem, tylko odmienionym w inny sposób"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_lemma(word1, word2):\n",
    "    # np. dla different_lemma('związkowi radzieckiemu', 'związku radzieckiego')\n",
    "    # False\n",
    "    doc1 = nlp(word1)\n",
    "    doc2 = nlp(word2)\n",
    "    res1 = []; res2 = []\n",
    "    for token in doc1:\n",
    "        res1.append((token.lemma_))\n",
    "    for token in doc2:\n",
    "        res2.append((token.lemma_))\n",
    "    return res1 != res2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja badająca czy słowa zaczynają się tą samą literą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_letters(word1, word2):\n",
    "    return word1[0].islower() == word2[0].islower() or word1[0].isupper() == word2[0].isupper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja zwracająca złe słowa (alternatywy) dla wskazanego dobrego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_bad_words(good_words, sort_ = True):\n",
    "    sl = []\n",
    "    for word in good_words: #dla każdego słowa w dobrych słowach\n",
    "        sl.append(write_bad_words_for_single(word)) # utwórz słownik {słowo: [lista_alternatywnych_slow]} i dodaj go do kolekcji sl\n",
    "    sort_sl = dict(pair for d in sl for pair in d.items()) # Utwórz z sl jeden słownik\n",
    "\n",
    "    def sort_by_values_len(dict):\n",
    "        # Posortuj słownik w zależności od długości [listy_alternatywnych_slow]\n",
    "        dict_len= {key: len(value) for key, value in dict.items()}\n",
    "        import operator\n",
    "        sorted_key_list = sorted(dict_len.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        sorted_dict = [{item[0]: dict[item [0]]} for item in sorted_key_list]\n",
    "        return sorted_dict\n",
    "    \n",
    "    # czy ma być zwrócona lista słowników {słowo: [lista_alternatywnych_slow]}  w formie posortowanej czy nie\n",
    "    if sort_:\n",
    "        return sort_by_values_len(sort_sl)\n",
    "    else:\n",
    "        return sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja losująca zdanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'zaburzeń': ()}, {'świadomości': ()}, {'umysłu': ()}, {'osoba': ()}, {'Psychoza': ()}, {'psychiatrii': ()}, {'stan': ()}, {'zakłóceń': ()}, {'percepcji': ()}]\n"
     ]
    }
   ],
   "source": [
    "def pick_sentence(best = True):\n",
    "    found = False\n",
    "    avoid = ['w.', 'w. ', ' r', 'r', 'r.', 'r ', 'm', ' m', 'm ', 'np', 'np.', 'K', 'C'] #unikaj tych \n",
    "    while not found: # Dopóki nie znaleziono właściwego zdania\n",
    "        los = random.randint(0,len(sentences)) # Losuj dowolną liczbę z ilości dostępnych zdać\n",
    "        wybrane_zdanie = sentences[los] # Wylosuj zdanie\n",
    "        good_words = find_good_word(wybrane_zdanie) # Znajdź w nim dobre słowa (kandydatów)\n",
    "        good_words = [w for w in good_words if w not in avoid]\n",
    "        #Jeżeli zdanie zaczyna się wielką literą i nie jest za krótkie i ma co najmniej 3 słowa kandydujące...\n",
    "        if len(good_words)>=3 and len(str(wybrane_zdanie).split()) >5 and str(wybrane_zdanie)[0].isupper():\n",
    "            \n",
    "            # napisz dla tych słów kandydujących słowa alternatywne\n",
    "            bad_words = write_bad_words(good_words)\n",
    "            if best:\n",
    "                # jeżeli dane słowo kandydujące ma co najmniej 2 alternatywy\n",
    "                if sum(map(len, bad_words[0].values())) >=2:\n",
    "                    found = True\n",
    "            else:\n",
    "                found = True\n",
    "    print(bad_words)\n",
    "    \n",
    "    #zwróć wybrane zdanie, wybrane słowo i numer zdania\n",
    "    return wybrane_zdanie, ''.join(bad_words[0].keys()), los\n",
    "\n",
    "picked_sentence, chosen_word, los = pick_sentence(best=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Psychoza (gr. psyche – dusza i osis – szaleństwo) – zaburzenie psychiczne definiowane w psychiatrii jako stan umysłu, w którym na skutek zakłóceń w postrzeganiu (percepcji) rzeczywistości, a czasem także zaburzeń świadomości, osoba ma trudność z odróżnieniem tego, co jest rzeczywiste, a co nie."
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picked_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zaburzeń'"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Psychoza (gr. psyche – dusza i osis – szaleństwo) – zaburzenie psychiczne definiowane w psychiatrii jako stan umysłu, w którym na skutek zakłóceń w postrzeganiu (percepcji) rzeczywistości, a czasem także _______________ świadomości, osoba ma trudność z odróżnieniem tego, co jest rzeczywiste, a co nie.'"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (los-1) >=0:\n",
    "    print(sentences[los-1])\n",
    "replace_word_in_sent(chosen_word, picked_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = write_bad_words_for_single(chosen_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zaburzeń': ()}"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---Poniższe potrzebne do przypadku gdy nie znajdzie się alternatywnych odpowiedzi---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deklinacja (rozwiązanie sieciowe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja znajdująca lemmę słowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_lemma(word):\n",
    "    doc = nlp(word)\n",
    "    for token in doc:\n",
    "        return str(token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zmień polskie znaki diakrytyczne na znaki w systemie unicode lub unicode UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_to(word, coding):\n",
    "    if coding=='unicode':\n",
    "        word.replace('ą','\\\\xc4\\\\x85').replace('ę','\\\\xc4\\\\x99').replace('ł','\\\\xc5\\\\82').replace('ś','\\\\xc5\\\\9b').replace('ć','\\\\xc4\\\\87').replace('ń','\\\\xc5\\\\84').replace('ó','\\\\xc3\\\\xb3').replace('ź','\\\\xc5\\\\ba').replace('ż','\\\\xc5\\\\bc')\n",
    "    if coding=='UTF-8':\n",
    "        for k,v in CODE_DICT.items():\n",
    "            word = word.replace(k, v[1])\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zmień znaki w systemie unicode UTF-8 na polskie diakrytyczne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_from(encoded_word): ###USUNĄĆ\n",
    "    if '%' in encoded_word: #UTF-8\n",
    "        for k,v in CODE_DICT.items():\n",
    "            encoded_word = encoded_word.replace(v[1],k)\n",
    "    return encoded_word\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popraw znaki na polskie litery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_word(word):\n",
    "    return word.replace('\\\\xc4\\\\x85','ą').replace('\\\\xc4\\\\x99','ę').replace('\\\\xc5\\\\x82','ł').replace('\\\\xc5\\\\x9b','ś').replace('\\\\xc4\\\\x87','ć').replace('\\\\xc5\\\\x84','ń').replace('\\\\xc3\\\\xb3','ó').replace('\\\\xc5\\\\ba','ź').replace('\\\\xc5\\\\xbc','ż')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja wyszukująca słowo w Wiktionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_declin_form_wiktionary(word_, full = True):\n",
    "    word = ret_lemma(word_)\n",
    "    url = 'https://en.wiktionary.org/wiki/' + word\n",
    "    r = requests.get(url)\n",
    "    tekst = str(r.content)\n",
    "    \n",
    "    if 'mianownik (kto? co?)' in tekst:\n",
    "        start_mian = '<th title=\"mianownik (kto? co?)'\n",
    "        start_dop = '<th title=\"dope\\\\xc5\\\\x82niacz (kogo? czego?)'    \n",
    "        start_cel = '<th title=\"celownik (komu? czemu?)'\n",
    "        start_bier = '<th title=\"biernik (kogo? co?)'\n",
    "        start_narz = '<th title=\"narz\\\\xc4\\\\x99dnik (kim? czym?)'\n",
    "        start_miejsc = '<th title=\"miejscownik (o kim? o czym?)'\n",
    "        start_wol = '<th title=\"wo\\\\xc5\\\\x82acz (o!)'\n",
    "        end = '</a>'\n",
    "        \n",
    "\n",
    "        mian = tekst.split(start_mian)[1].split(end)[0].split('>')[-1]\n",
    "        dop = tekst.split(start_dop)[1].split(end)[0].split('>')[-1]\n",
    "        cel = tekst.split(start_cel)[1].split(end)[0].split('>')[-1]\n",
    "        bier = tekst.split(start_bier)[1].split(end)[0].split('>')[-1]\n",
    "        narz = tekst.split(start_narz)[1].split(end)[0].split('>')[-1]\n",
    "        miejs = tekst.split(start_miejsc)[1].split(end)[0].split('>')[-1]\n",
    "        wol = tekst.split(start_wol)[1].split(end)[0].split('>')[-1]\n",
    "\n",
    "        declination_list = [mian, dop, cel, bier, narz, miejs, wol]\n",
    "        if word_ not in list(map(correct_word,declination_list)):\n",
    "            \n",
    "            end = '</a></span>\\\\n</td></tr>'\n",
    "            mian = tekst.split(start_mian)[1].split(end)[0].split('>')[-1]\n",
    "            dop = tekst.split(start_dop)[1].split(end)[0].split('>')[-1]\n",
    "            cel = tekst.split(start_cel)[1].split(end)[0].split('>')[-1]\n",
    "            bier = tekst.split(start_bier)[1].split(end)[0].split('>')[-1]\n",
    "            narz = tekst.split(start_narz)[1].split(end)[0].split('>')[-1]\n",
    "            miejs = tekst.split(start_miejsc)[1].split(end)[0].split('>')[-1]\n",
    "            wol = tekst.split(start_wol)[1].split(end)[0].split('>')[-1]\n",
    "            \n",
    "            declination_list = [mian, dop, cel, bier, narz, miejs, wol]\n",
    "            \n",
    "        declination_list_corr = list(map(correct_word,declination_list))\n",
    "    \n",
    "        if full:\n",
    "            return declination_list_corr\n",
    "        else:\n",
    "            #przypadki = ['mianownik', 'dopełniacz', 'celownik', 'biernik', 'narzędnik', 'miejscownik', 'wołacz']\n",
    "            \n",
    "            for n,_ in enumerate(declination_list):\n",
    "                if correct_word(_) == word_:\n",
    "                    return przypadki[n]\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "            return declination_list_corr\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Przykłady działania ww. funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['księgozbiory',\n",
       " 'księgozbiorów',\n",
       " 'księgozbiorom',\n",
       " 'księgozbiory',\n",
       " 'księgozbiorami',\n",
       " 'księgozbiorach',\n",
       " 'księgozbiory']"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_declin_form_wiktionary('księgozbiory', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['żółw', 'żółwia', 'żółwiowi', 'żółwia', 'żółwiem', 'żółwiu', 'żółwiu']"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_declin_form_wiktionary('żółw', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'narzędnik'"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_declin_form_wiktionary('przełącznikiem', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja zmieniająca dekliancję słowa na podstawie podanego przypadku "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_declination(word, form):\n",
    "    declin_list = ret_declin_form_wiktionary(word, True)\n",
    "    declin_form = ret_declin_form_wiktionary(word, False)\n",
    "    if declin_list != False:\n",
    "        for n,w in enumerate(declin_list):\n",
    "            if przypadki[n] == form:\n",
    "                return str(declin_list[n])\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deklinacja (rozwiązanie lokalne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "rzeczowniki = [json.loads(line) for line in open('nouns.json', 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_declin_form(word, full = False):\n",
    "    #jeżeli full = False funkcja zwraca przypadek rzeczownika \n",
    "    #jeżeli full = True funkcja zwraca pełną odmianę przez przypadki\n",
    "            \n",
    "    lem_szukane_slowo = ret_lemma(word) # słowo w podstawowej formie\n",
    "    \n",
    "    \n",
    "    #wydobądź całą odmianę słowa z lokalnego zbioru rzeczowników\n",
    "    def wiki_word(lem_word):\n",
    "        wiki = 'https://en.wiktionary.org/wiki/' \n",
    "        wiki_ulr = wiki + change_to(lem_word, 'UTF-8')\n",
    "        for entry in rzeczowniki:\n",
    "            if entry['url'] == wiki_ulr:\n",
    "                return entry\n",
    "            \n",
    "    declin_dict = wiki_word(lem_szukane_slowo)\n",
    "    \n",
    "    if declin_dict: # jeżeli słownik nie jest pusty\n",
    "        for k,v in declin_dict['case_forms']['plural'].items():\n",
    "            if change_to(v, 'unicode') == word:\n",
    "                return DECLINATION_FORM[k]\n",
    "        for k,v in declin_dict['case_forms']['singular'].items():\n",
    "            if change_to(v, 'unicode') == word:\n",
    "                return DECLINATION_FORM[k]\n",
    "        return False\n",
    "    else: # jeżeli jest pusty\n",
    "        \n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Przykład"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'objaw'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ret_lemma('Objawami')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dopełniacz'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_declin_form('energii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dopełniacz'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_declin_form('węgla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['krzesło', 'krzesła', 'krzesłu', 'krzesło', 'krzesłem', 'krześle', 'krzesło']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_declin_form_wiktionary('krzesła')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ciepło', 'ciepła', 'ciepłu', 'ciepło', 'ciepłem', 'cieple', 'ciepło']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_declin_form_wiktionary('ciepło')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['objawy', 'objawów', 'objawom', 'objawy', 'objawami', 'objawach', 'objawy']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_declin_form_wiktionary('objawy', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcja odnajdująca słowa podobne do wybranego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### UWAGA! Proces czasochłonny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_words():\n",
    "    cand_dict = dict()\n",
    "    for key in doc: #dla każdego słowa w tekście\n",
    "        #jeżeli jest to takie samo POS jak wybrane słowo i można dla niego znaleźć wektor\n",
    "        if nlp(chosen_word)[0].pos_ == key.pos_ and nlp.vocab[str(key)].has_vector:\n",
    "            score = nlp(str(chosen_word)).similarity(nlp(str(key))) #określ procentową wartość podobieństwa do wybranego słowa\n",
    "            cand_dict[str(key)] = score # i przypisz temu słowu score\n",
    "    cand_dict_s = [(k,v) for k,v in sorted(cand_dict.items(), key = lambda item: item[1], reverse = True)] #uporządkuj słowa względem procentowego podobieństwa\n",
    "    chosen_word_declin = ret_declin_form_wiktionary(chosen_word, False) #sprawdź w jakim przypadku występuje właściwe słowo\n",
    "    cand_dict_s_new = [(elem[0], elem[1]) for elem in cand_dict_s if different_lemma(chosen_word, elem[0])][:3] # z listy wybranych słów zostaw tylko 3 takie, które\n",
    "    cand_dict_s_new_words_only = [elem[0] for elem in cand_dict_s_new]\n",
    "    #mają inną lemmę niż słowo właściwe\n",
    "    \n",
    "    if chosen_word_declin != False:\n",
    "        ans = [change_declination(elem, chosen_word_declin) for elem in cand_dict_s_new_words_only]\n",
    "        return ans\n",
    "    else:\n",
    "        return cand_dict_s_new_words_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_answers = similar_words()\n",
    "random.shuffle(bad_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['psychopatologii', 'psychoz', 'objawów']"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "if answers[chosen_word] == tuple():\n",
    "    answers[chosen_word] = bad_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zaburzeń': ['psychopatologii', 'psychoz', 'objawów']}"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wymieszaj odpowiedzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_ans = list(answers.values())[0] + list(answers.keys())\n",
    "random.shuffle(prep_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Psychoza (gr. psyche – dusza i osis – szaleństwo) – zaburzenie psychiczne definiowane w psychiatrii jako stan umysłu, w którym na skutek zakłóceń w postrzeganiu (percepcji) rzeczywistości, a czasem także _______________ świadomości, osoba ma trudność z odróżnieniem tego, co jest rzeczywiste, a co nie.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf61d5a51dc144b5bab9e038f639148c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='psychopatologii', style=ButtonStyle()), Button(description='zaburzeń', styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "button1, button2, button3, button4 = [widgets.Button(description=w) for w in prep_ans]\n",
    "out = widgets.Output()\n",
    "def on_button_clicked(b):\n",
    "    if b.description == chosen_word:\n",
    "        b.style.button_color = 'lightgreen'\n",
    "        with out:\n",
    "            print('Poprawna odpowiedź')\n",
    "    else:\n",
    "        b.button_style = 'danger'\n",
    "        with out:\n",
    "            print('Błędna odpowiedź')\n",
    "if (los-1) >=0:\n",
    "    print(sentences[los-1])\n",
    "print(replace_word_in_sent(chosen_word, picked_sentence))\n",
    "button1.on_click(on_button_clicked)\n",
    "button2.on_click(on_button_clicked)\n",
    "button3.on_click(on_button_clicked)\n",
    "button4.on_click(on_button_clicked)\n",
    "widgets.VBox([button1, button2, button3, button4, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
